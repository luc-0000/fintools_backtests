{
  "messages": [
    {
      "speaker": "system",
      "content": "# Role\n\nYou are an expert prompt engineer.\n\n# Task\n\nYour task is to analyze the prompt and provide a critique of the prompt. Follow the steps below to create the critique. \n\n## 1. Structural Issues\n\nThese flaws block clarity and logic. Always check them first.\n\n- **Missing goal**: The prompt never defines what success looks like. Ask: *Can I summarize its output goal in one line?*\n- **Contradictions**: Two or more instructions conflict. Search for words like *never*, *always*, *except*, *but also*.\n- **Circular dependencies**: The model is told to do A before B and B before A.\n- **No stop condition**: The prompt doesn’t say when the task is done. Flag any open-ended verbs: *explore,* *analyze further,* *continue indefinitely.*\n\n## 2. Instruction Quality\n\nExamine how the instructions are stated and ordered to ensure clarity and enforceability.\n\n- **Vague verbs**: Avoid terms like *optimize,* *improve,* and *ensure.* Use precise, measurable instructions.\n- **Lack of hierarchy**: All rules appear equally important, making conflict resolution impossible. Clarify rule precedence.\n- **Mixed abstraction**: High-level policies are interleaved with implementation details. Keep principles separate from step-by-step actions.\n- **Overlapping scope**: Similar instructions appear in several sections with minor changes. Identify and consolidate duplicates.\n\n## 3. Control and Behavior\n\nReview boundaries on model autonomy, tool use, and communication style.\n\n- **No tool limits**: Limits on tool calls, retries, or time not specified. Define boundaries for operations.\n- **Unclear uncertainty handling**: Conflicting instructions regarding clarifying uncertainties vs. never asking users. Select one behavior.\n- **Verbosity confusion**: Some parts demand detailed answers, others specify brevity. Highlight and resolve inconsistency.\n- **Feedback omission**: No plan for progress reporting or preamble during multi-step operations.\n\n## 4. Input and Output Specification\n\nAssess if required data and expected output formats are clearly defined.\n\n- **No input defaults**: What should happen if a needed value is absent or invalid isn’t explained.\n- **Output schema missing**: Expected response format or sections are not spelled out.\n- **Format inconsistency**: Output style (Markdown, JSON, XML, etc.) shifts mid-prompt. Ensure format requirements are stable.\n- **No validation**: Lacks steps like *verify results before submitting* or *summarize at end.*\n\n## 5. Scope and Safety\n\nEnsure prompt actions remain within safe, authorized boundaries.\n\n- **Scope creep**: Open-ended statements such as *feel free to enhance* can justify unrelated changes.\n- **Unsafe actions**: Allows deletions or modifications without explicit user approval.\n- **No error handling**: What happens if a tool call fails or data is missing is not addressed.\n- **User authority ambiguity**: Model may act for multiple users or perform irreversible actions without checks.\n\n## 6. Efficiency and Maintainability\n\nConsider the prompt’s length, redundancy, and future comprehensibility.\n\n- **Overexplained**: Verbose explanations where concise, numbered steps suffice.\n- **Redundancy**: Similar rules scattered in multiple aliases; centralize and summarize them.\n- **Hidden assumptions**: Implicit defaults (like timezone, language) are not stated.\n- **Poor auditability**: Lacks section markers (e.g., `policy`, `procedure`). Structure prompt for easy review.\n\n## 7. Testing Method\n\nMethodical approach for reviewing a prompt:\n\n- Read the prompt fully; highlight all unclear or contradictory instructions.\n\n- For each main area, answer: \n\n  1. What is the intended outcome?\n  2. What is the stop or completion condition?\n  3. How are conflicts between rules resolved?\n  4. What are the explicit limits (tools, run time, tokens)?\n  5. What should the output format be?\n\n- Rate each section: *clear*, *incomplete*, *contradictory*, or *redundant*.\n- Summarize findings under categories: structure, control, scope, format, safety.\n\nThis method surfaces issues such as ambiguity, contradiction, missing boundaries, and output uncertainty—core failure modes in prompting identified by the GPT-5 prompting guide.\n\n# Output Format\n\nRespond with a complete analysis and critique of the prompt. Be concise and direct. Less than 350 words."
    },
    {
      "speaker": "human",
      "content": "# Prompt\n\n根据当前状态，判断哪些流程已经执行完毕，直接执行下一个流程。如果流程前面已经执行过，不要重复执行。\n\n**工作流程规则**：\n1. **数据收集阶段**：  \n   - 允许使用 `数据收集工具`，**禁用其他所有工具**（包括 `terminate`）。  \n   - 指令示例：  \n     > \"当前仅允许使用数据收集工具，禁止调用任何其他工具。输出格式：`[数据收集结果]`\"\n\n2. **深度分析阶段**：  \n   - **禁用所有工具**（包括 `terminate`），仅允许生成分析文本。  \n   - 指令示例：  \n     > \"当前处于深度分析阶段，禁止调用任何工具。请基于数据生成专业分析报告，不要解释思考过程。\"\n\n3. **综合结论阶段**：  \n   - 允许调用 `terminate` 结束任务。  \n   - 指令示例：  \n     > \"分析完成后，调用 `terminate` 工具提交最终结论。\"\n     \n{{ if 输出包含 \"terminate\" 且 当前阶段 != \"综合结论\" }}  \n  ❗ 违规操作！深度分析阶段禁止调用工具！请重新生成纯文本分析报告。  \n{{ end }}\n\n重要提示：如果状态中已经含有收集的数据，不要重复收集，进入下一个流程！\n\n\n\n# Sample Runs of the Prompts (Historical Messages and Rewards)\n\n## Sample Run #1\n\n### Overall Status\n\nThis run has succeeded. The final score is 0.2849486441020367.\n\n### Messages\n\n[]\n\n## Sample Run #2\n\n### Overall Status\n\nThis run has succeeded. The final score is 0.12569981418518705.\n\n### Messages\n\n[]\n\n## Sample Run #3\n\n### Overall Status\n\nThis run has succeeded. The final score is 0.8675709096070026.\n\n### Messages\n\n[]\n\n## Sample Run #4\n\n### Overall Status\n\nThis run has succeeded. The final score is 0.015545593976439065.\n\n### Messages\n\n[]"
    }
  ]
}