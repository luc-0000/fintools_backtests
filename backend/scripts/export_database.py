#!/usr/bin/env python
# encoding=utf8
"""
æ•°æ®åº“å¯¼å‡ºè„šæœ¬

æ”¯æŒåŠŸèƒ½ï¼š
1. å¯¼å‡ºä¸º SQL æ–‡ä»¶ï¼ˆå¯ç”¨äºå®Œæ•´æ¢å¤ï¼‰
2. å¯¼å‡ºä¸º JSON æ–‡ä»¶ï¼ˆä¾¿äºæŸ¥çœ‹å’Œéƒ¨åˆ†æ¢å¤ï¼‰
3. è‡ªåŠ¨æŒ‰æ—¶é—´æˆ³å‘½åå¯¼å‡ºæ–‡ä»¶

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/export_database.py                    # å¯¼å‡ºä¸º SQL å’Œ JSON
    python scripts/export_database.py --sql-only         # ä»…å¯¼å‡º SQL
    python scripts/export_database.py --json-only        # ä»…å¯¼å‡º JSON
    python scripts/export_database.py --output-dir ./backups
"""

import os
import sys
import json
import subprocess
from datetime import datetime
from pathlib import Path
import argparse

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from end_points.init_global import init_global, load_config_file
from end_points.config.global_var import global_var
from db.mysql.db_schemas import (
    Stock, StockIndex, UpdatingStock, StocksInPool,
    Pool, PoolStock, Rule, RulePool, StockRuleEarn, PoolRuleEarn,
    Simulator, SimTrading, SimulatorConfig, AgentTrading
)


def get_db_config(config_file='../../service.conf'):
    """ä»é…ç½®æ–‡ä»¶è·å–æ•°æ®åº“è¿æ¥ä¿¡æ¯"""
    config = load_config_file(config_file)
    return {
        'host': config.get('DB_HOST', 'localhost'),
        'port': config.get('DB_PORT', 3306),
        'user': config.get('DB_USER', 'root'),
        'password': config.get('DB_PASSWORD', ''),
        'database': config.get('DB_NAME', 'fintools_backtest')
    }


def export_to_sql(db_config, output_file):
    """ä½¿ç”¨ mysqldump å¯¼å‡ºæ•°æ®åº“ä¸º SQL æ–‡ä»¶"""
    print(f"ğŸ”§ æ­£åœ¨å¯¼å‡ºæ•°æ®åº“åˆ° SQL æ–‡ä»¶: {output_file}")

    cmd = [
        'mysqldump',
        f'-h{db_config["host"]}',
        f'-P{db_config["port"]}',
        f'-u{db_config["user"]}',
        f'-p{db_config["password"]}',
        '--single-transaction',
        '--quick',
        '--lock-tables=false',
        '--routines',
        '--triggers',
        '--events',
        db_config['database']
    ]

    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            result = subprocess.run(cmd, stdout=f, stderr=subprocess.PIPE, text=True, check=True)

        file_size = os.path.getsize(output_file) / (1024 * 1024)  # MB
        print(f"âœ… SQL å¯¼å‡ºæˆåŠŸ! æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
        return True

    except subprocess.CalledProcessError as e:
        print(f"âŒ SQL å¯¼å‡ºå¤±è´¥: {e.stderr}")
        return False
    except FileNotFoundError:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° mysqldump å‘½ä»¤")
        print("   è¯·å®‰è£… MySQL å®¢æˆ·ç«¯å·¥å…·:")
        print("   - macOS: brew install mysql-client")
        print("   - Ubuntu: sudo apt-get install mysql-client")
        return False


def export_table_to_json(db_session, table_class, table_name, output_dir):
    """å¯¼å‡ºå•ä¸ªè¡¨ä¸º JSON æ–‡ä»¶"""
    print(f"  ğŸ“‹ å¯¼å‡ºè¡¨: {table_name}")

    try:
        # æŸ¥è¯¢æ‰€æœ‰æ•°æ®
        records = db_session.query(table_class).all()

        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        data = []
        for record in records:
            record_dict = {}
            for c in record.__table__.columns:
                value = getattr(record, c.name)
                # å¤„ç† datetime å¯¹è±¡
                if isinstance(value, datetime):
                    value = value.isoformat()
                record_dict[c.name] = value
            data.append(record_dict)

        # å†™å…¥ JSON æ–‡ä»¶
        output_file = os.path.join(output_dir, f"{table_name}.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"    âœ… {table_name}: {len(data)} æ¡è®°å½•")
        return len(data)

    except Exception as e:
        print(f"    âŒ {table_name} å¯¼å‡ºå¤±è´¥: {str(e)}")
        return 0


def export_to_json(db_config, output_dir):
    """ä½¿ç”¨ SQLAlchemy å¯¼å‡ºæ‰€æœ‰è¡¨ä¸º JSON æ–‡ä»¶"""
    print(f"ğŸ“Š æ­£åœ¨å¯¼å‡ºæ•°æ®åº“åˆ° JSON ç›®å½•: {output_dir}")

    # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
    try:
        config_file = '../../service.conf'
        init_global(config_file)
        db = global_var["db"]

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)

        # å®šä¹‰è¦å¯¼å‡ºçš„è¡¨
        tables = [
            (Stock, 'stock'),
            (StockIndex, 'stock_index'),
            (UpdatingStock, 'updating_stock'),
            (StocksInPool, 'stocks_in_pool'),
            (Pool, 'pool'),
            (PoolStock, 'pool_stock'),
            (Rule, 'rule'),
            (RulePool, 'rule_pool'),
            (StockRuleEarn, 'stock_rule_earn'),
            (PoolRuleEarn, 'pool_rule_earn'),
            (Simulator, 'simulator'),
            (SimTrading, 'simulator_trading'),
            (SimulatorConfig, 'simulator_config'),
            (AgentTrading, 'agent_trading'),
        ]

        total_records = 0
        # å¯¼å‡ºæ¯ä¸ªè¡¨
        for table_class, table_name in tables:
            count = export_table_to_json(db.session, table_class, table_name, output_dir)
            total_records += count

        # åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶
        metadata = {
            'export_time': datetime.now().isoformat(),
            'database': db_config['database'],
            'total_tables': len(tables),
            'total_records': total_records,
            'tables': [
                {'name': name, 'model': model.__name__}
                for model, name in tables
            ]
        }

        metadata_file = os.path.join(output_dir, '_metadata.json')
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

        print(f"\nâœ… JSON å¯¼å‡ºæˆåŠŸ! å…± {len(tables)} ä¸ªè¡¨, {total_records} æ¡è®°å½•")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        return True

    except Exception as e:
        print(f"âŒ JSON å¯¼å‡ºå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def main():
    parser = argparse.ArgumentParser(description='æ•°æ®åº“å¯¼å‡ºè„šæœ¬')
    parser.add_argument('--sql-only', action='store_true', help='ä»…å¯¼å‡º SQL æ–‡ä»¶')
    parser.add_argument('--json-only', action='store_true', help='ä»…å¯¼å‡º JSON æ–‡ä»¶')
    parser.add_argument('--output-dir', type=str, default='./backups', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--config', type=str, default='../../service.conf', help='é…ç½®æ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    # è·å–æ•°æ®åº“é…ç½®
    db_config = get_db_config(args.config)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_dir = os.path.join(args.output_dir, f"backup_{timestamp}")
    os.makedirs(backup_dir, exist_ok=True)

    print(f"\n{'='*60}")
    print(f"ğŸ—„ï¸  æ•°æ®åº“å¯¼å‡ºå·¥å…·")
    print(f"{'='*60}")
    print(f"ğŸ“… æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ—ƒï¸  æ•°æ®åº“: {db_config['database']}")
    print(f"ğŸŒ ä¸»æœº: {db_config['host']}:{db_config['port']}")
    print(f"{'='*60}\n")

    success = True

    # å¯¼å‡º SQL
    if not args.json_only:
        sql_file = os.path.join(backup_dir, f"{db_config['database']}_{timestamp}.sql")
        if not export_to_sql(db_config, sql_file):
            success = False

    # å¯¼å‡º JSON
    if not args.sql_only:
        json_dir = os.path.join(backup_dir, 'json_export')
        if not export_to_json(db_config, json_dir):
            success = False

    print(f"\n{'='*60}")
    if success:
        print(f"âœ… å¯¼å‡ºå®Œæˆ! å¤‡ä»½ä½ç½®: {backup_dir}")
    else:
        print(f"âš ï¸  å¯¼å‡ºå®Œæˆï¼Œä½†éƒ¨åˆ†æ“ä½œå¯èƒ½å¤±è´¥")
    print(f"{'='*60}\n")

    return 0 if success else 1


if __name__ == '__main__':
    sys.exit(main())